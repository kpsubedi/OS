Introduction
------------
- The computer industry is undergoing, if not another revolution, certainly a vigorous shaking-up. The major chip manufactures have, for the time being at
least, given up trying to make processors run faster. Moore's Law has not been repealed: each year, more and more transistors fit into the same space, but 
their clock speed cannot be increased without overheating. 

- Instead, manufactures are turning to "multicore" architectures, in which multiple processors (cores) communicate directly through shared hardware caches. 
Multiprocessor chips make computing more effective by exploiting parallelism: harnessing multiple processors to work on a single task.

- The spread of multiprocessor architecures will have a pervasive effect on how we develop software. Until recently, advances in technology meant advances 
in clock speed, so software would effectively "speed up" by itself over time. Now, however, this free ride is over. Advances in technology will mean 
increased parallelism and not increased clock speed, and exploiting such parallelism is one of the outstanding challenges of modern Computer Science.

- This book focuses on how to program multiprocessors that communicate via a shared memory. Such systems are often called shared-memory multiprocessors 
or, more recently, multicores. Programming challenges arise at all scales of multiprocessor systems-at a very small scale, processors within a single 
chip need to coordinate access to a shared memory location, and on a large scale, processors in a supercomputer need to coordinate the routing of data.

- Multiprocessor programming is challenging because modern computer systems are inherently asynchronous: activities can be 
halted or delayed without warning by
  - interrupts,
  - preemption,
  - cache misses,
  - failures, and
  - other events. 

- These delays are inherently unpredictable, and can vary enormously in scale:
    - a cache miss might delay a processor for fewer than ten instructions,
    - a page fault for a few million instructions, and
    - operating system preemption for hundreds of millions of instructions. 

- We approach multiprocessor programming from two complementary directions: principles and practice. 

- In the principles part of this book, we focus on computability: figuring out what can be computed in an asynchronous 
concurrent environment. We use an idealized model of computation in which multiple concurrent threads manipulate a set 
of shared objects. The sequence of the thread operations on the objects is called the concurrent program or concurrent 
algorithm. This model is essentially the model presented by tje Java, C#, or C++ thread packages. 

- Surprisingly, there are easy-to-specify shared objects that cannot be implemented by any concurrent algorithm. It is 
therefore important to understand what not to try, before proceeding to write multiprocessor programs. Many of the issues 
that will land multiprocessor programmers in trouble
  - are consequences of fundamental limitations of the computational model, so we view the acquisition of a basic understanding 
of concurrent shared-memory computability as a necessary step. 

- The chapters dealing with principles take the reader through a quick tour of asynchronous computability, attempting to 
expose various computability issues, and how they are addressed through the use of hardware and software mechanisms. 

- An important step 
























